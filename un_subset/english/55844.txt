%%%CLIMATE CHANGE|ENVIRONMENTAL IMPACT ASSESSMENT|ENVIRONMENTAL MONITORING|

UNITED NATIONS Distr. GENERAL FCCC/SBSTA/2010/5 16 April 2010 Original: English SUBSIDIARY BODY FOR SCIENTIFIC AND TECHNOLOGICAL ADVICE Thirty-second session Bonn, 31 May to 9 June 2010 Item 3 of the provisional agenda Nairobi work programme on impacts, vulnerability and adaptation to climate change Synthesis report on efforts undertaken to monitor and evaluate the implementation of adaptation projects, policies and programmes and the costs and effectiveness of completed projects, policies and programmes, and views on lessons learned, good practices, gaps and needs Note by the secretariat Contents Paragraphs Page Introduction Mandate The Subsidiary Body for Scientific and Technological Advice, in its conclusions at its twenty-eighth session on the Nairobi work programme on impacts, vulnerability and adaptation to climate change, requested the secretariat to prepare, by its thirty-second session, a synthesis report based on information submitted by Parties and relevant organizations on efforts undertaken to monitor and evaluate the implementation of adaptation projects, policies and programmes and the costs and effectiveness of completed projects, policies and programmes, and views on lessons learned, good practices, gaps and needs. The report was to also include information from other relevant sources and prepared with a view to facilitating the development of indicators for assessing the implementation of adaptation projects, policies and programmes. Scope of the note This document synthesizes the views and information submitted on efforts undertaken to monitor and evaluate the implementation of adaptation projects, policies and programmes, and the costs and effectiveness of completed projects, policies and programmes as well as views on lessons learned, good practices, gaps and needs. Submissions were received from one Party (Sweden on behalf of the European Community, now the European Union (EU), and its member States), representing the views of 32 Parties, and from one non-governmental organization (Wetlands International). In addition, other relevant sources of information were analysed and integrated into this report to provide a more comprehensive picture of progress being made, and to provide insight into the issues surrounding the development of indicators for assessing the implementation of planned adaptation. Besides studying projects and programmes, the report also considers efforts in monitoring and evaluating adaptation policies, strategies and plans. Background The overall objective of the Nairobi work programme is to assist all Parties, in particular developing countries, including the least developed countries (LDCs) and small island developing States, to improve their understanding and assessment of impacts, vulnerability and adaptation, and to make informed decisions on practical adaptation actions and measures to respond to climate change on a sound scientific, technical and socio-economic basis, taking into account current and future climate change and variability. The Nairobi work programme comprises nine work areas, through which it aims to achieve its objectives. This document is prepared under the sixth work area, "Adaptation planning and practices", which seeks to advance the subthemes stated in paragraphs 3 (b) (ii) and (iv) of the annex to decision 2/CP.11, namely "Collecting, analysing and disseminating information on past and current practical adaptation actions and measures, including adaptation projects, short- and long-term adaptation strategies, and local and indigenous knowledge" and "Facilitating communication and cooperation among and between Parties and relevant organizations, business, civil society and decision makers, and other stakeholders". Efforts undertaken to monitor and evaluate the implementation of adaptation projects, policies and programmes Common approaches and concepts Monitoring and evaluation of projects, policies and programmes forms an important part of the adaptation process. Ultimately, successful adaptation will be measured by how well different measures contribute to effectively reducing vulnerability and building resilience. Lessons learned, good practices, gaps and needs identified during the monitoring and evaluation of ongoing and completed projects, policies and programmes will inform future measures, creating an iterative and evolutionary adaptation process. Section B of this chapter reports on current monitoring and evaluation efforts being undertaken by Parties and organizations, while the remainder of this section introduces relevant approaches and concepts, drawn from submissions and the literature, associated with monitoring and evaluation and the development and use of indicators. Monitoring and evaluation, including of costs and effectiveness Given the complexity and long-term nature of climate change, it is essential that adaptation be designed as a continuous and flexible process and subjected to periodic review. The implementation of adaptation needs to be monitored, evaluated regularly and revised in terms of both the validity of the underlying scientific assumptions and the appropriateness of projects, policies and programmes, including their effectiveness, efficiency and overall utility. Already, many adaptation decision frameworks, including those developed by the United Kingdom of Great Britain and Northern Ireland Climate Impacts Programme (UKCIP) and the United Nations Development Programme (UNDP), include monitoring and evaluation as an integral part of the adaptation cycle. The purpose of monitoring is to keep track of progress made in implementing a specific adaptation measure in relation to its objectives and inputs, which include financial resources. Monitoring enables planners and practitioners to improve adaptation efforts by adjusting processes and targets. Evaluation is a process for systematically and objectively determining the effectiveness of an adaptation measure in the light of its objectives. Assessing effectiveness involves two questions: first, have the objectives and targets been achieved; and second, can this be attributed to the measure taken? Besides effectiveness, other aspects that are frequently evaluated include the relevance of a measure, its efficiency and its overall utility. The figure below illustrates a possible framework for monitoring and evaluating adaptation. In this context, "outputs" are understood as measurable products and services which result from an adaptation project, policy or programme; "outcomes" as the short- and medium-term effects of an adaptation measure's outputs; and finally, "impacts" are understood as positive and negative long-term effects on identifiable groups and systems. Framework for evaluating adaptation projects, policies and programmes The information reviewed suggests that monitoring and evaluation may be carried out at several stages of the lifetime of adaptation projects, policies and programmes, including: During implementation (ongoing monitoring and regular evaluation to assess progress made); Immediately after conclusion (`terminal' evaluation to assess efficiency and preliminary effectiveness); Some years after conclusion (post evaluation to assess effectiveness and overall utility of the measure). Successful monitoring and evaluation requires two basic questions to be answered up front: what has to be monitored and evaluated (scope), and who has to monitor and evaluate it (responsibilities)? Whereas monitoring, reporting and review are usually undertaken by those implementing the project, policy or programme, evaluation are usually undertaken by independent experts taking into account the results of the monitoring. When the questions in paragraph 11 above have been addressed, a monitoring and evaluation system can be put in place. According to the UKCIP adaptation wizard tool, the system should define measures of success; consider performance relative to expectations; describe how results of the monitoring and evaluation will be fed back into the ongoing adaptation policy process; and allow for the inclusion of new information and revision of adaptation projects, policies and programmes. Developing and using adaptation indicators Monitoring and evaluation of the implementation of adaptation projects, policies and programmes may take place through the use of indicators. Indicators can be used to simplify, quantify, standardize and communicate complex and often disparate data and information, and may provide the basis for assessments of efficiency and effectiveness. A technical paper from the European Topic Centre on Air and Climate Change recommends that planners and practitioners consider the following issues when developing adaptation indicators: Availability: do appropriate data and indicators already exist? Potential availability: are reliable data available in areas where indicators have not yet been developed? Representativeness: are indicators available to measure progress on important or determining factors, rather than less significant issues? Continuity: are data readily available over an unbroken time series for the indicators under consideration? In developing its National Climate Change Strategy, Costa Rica identified additional criteria for selecting indicators, including whether the indicator is easily measurable, whether the indicator is applicable to a range of adaptation outcomes at different spatial and temporal scales and whether the costs of obtaining data are justified. These considerations are consistent with calls identified in the literature for indicators to be formulated in a specific, measurable, achievable, relevant and time-bound (SMART) manner. Indicators can be developed to focus on one of two aspects of monitoring and evaluating adaptation: to facilitate monitoring of progress in developing and implementing adaptation measures in particular (so-called process-based indicators), or to measure the effectiveness of such adaptation measures in general (so-called outcome-based indicators). The relationship between process-based and outcome-based indicators is shown in table 1. Table 1. Relationship between process-based and outcome-based adaptation indicators Process-based adaptation indicators Outcome-based adaptation indicators Development of adaptation policies (e.g. preparation of catchment-specific flood management policies and plans) Implementation of adaptation programmes and projects (e.g. construction of flood protection schemes) Effectiveness of adaptation (e.g. reduction in economic losses due to floods) Source: Adapted from Harley M and van Minnen J. 2009. Development of Adaptation Indicators. ETC/ACC Technical Paper 2009/6. Available at <http://air-climate.eionet.europa.eu/docs//ETCACC_ TP_2009_6_Adaptation_Indicators.pdf>. Although process-based indicators are used to measure the development and implementation of adaptation projects, policies and programmes, there is no guarantee that successful implementation will also mean that effective adaptation is taking place. The task of measuring the effectiveness of adaptation measures is challenging, and the development of appropriate outcome-based indicators should follow agreed adaptation objectives and targets. In addition to measuring development, implementation and effectiveness of adaptation initiatives, it is necessary to consider other factors that may contribute to or hinder the adaptation process and its outcomes. Hence, indicators of drivers of adaptation, such as relevant legislation, barriers, such as a possible lack of compliance and enforcement of legislation, and other developments that decease or increase vulnerability, such as improvements in the health or education sector, are also desirable. As a result of comprehensive monitoring and evaluation using a range of indicators, it should be possible to measure the effectiveness of adaptation and to identify good practices and lessons learned so that adaptation projects, policies and programmes can be enhanced. Challenges in developing and using adaptation indicators Developing and using indicators for monitoring and evaluating the implementation and effectiveness of adaptation is challenging, in particular for outcome-based indicators and assessing the effectiveness of adaptation projects, policies and programmes. Challenges may arise from: The nature of adaptation; A lack of agreed metrics; The difficulty of attributing cause and effect; Unintended negative side effects. First, the nature of adaptation itself makes it difficult to develop outcome-based indicators. Difficulties arise from the long timescales associated with climate change and its impacts; uncertainty associated with projected impacts and the related challenges of defining a long-term vision of the outcome of adaptation and agreeing on levels of acceptable risk; and the multi-sectoral nature of adaptation and the involvement at different times and places of a large number of stakeholders who may all have their own requirements for indicators and appropriate monitoring and evaluation systems. In addition, many adaptation measures have a reverse logic, that is, the measure is by default successful when no impacts are experienced. For example, if no extreme events occur, such as droughts or floods, it is difficult to judge the effectiveness of the measure. One way to overcome this difficulty would be to apply proxy indicators such as those measuring adaptive capacity. Unlike in climate change mitigation, where carbon dioxide equivalence can be used as a common metric, adaptation lacks an agreed metric to determine effectiveness. Therefore the outcomes of evaluations of adaptation projects, policies and programmes may not always be directly comparable. For example, a goal of adaptation is to reduce vulnerability. However, the concept of vulnerability has multiple meanings for different stakeholders depending on whether the emphasis is on environmental, social or economic factors. As such, vulnerability assessments require value judgements, and any attempt to define and measure vulnerability must be the result of a consultative, stakeholder-driven process, rather than the result of technical analysis resulting in a simple metric. A further complication in developing adaptation indicators relates to the difficulty in separating progress in adaptation from progress achieved by broader sectoral policies - in other words, the attribution of cause and effect. As adaptation entails a range of projects, policies and programmes across sectors and levels, their effect may be difficult to distinguish from the effects of other sectoral activities. Whether or not attribution is important depends on why monitoring and evaluation are being carried out. If indicators are needed in order to show that a particular project, policy or programme has been cost-effective, then it will be essential to find ways to attribute measured successes to those individual actions. But if the only purpose of developing an indicator (or set of indicators) is to measure the status of the system and to observe trends, then attribution of any change identified by those indicators to particular actions or agents is less important. The Organisation for Economic Co-operation and Development (OECD) recommends caution in using indicators, as their application may have unintended negative side effects. Using `percentage of population living in a flood plain' as an indicator of effective adaptation, for example (where a low percentage would be considered a step towards successful adaptation), could lead governments to adopt policies of resettlement and relocation, which, in some cases, may not actually benefit the households concerned. After the floods in Mozambique in 2000, many households were relocated away from the flood plains in which they lived. However, OECD found that many of the people concerned were not provided with new homes, sufficient farmland or adequate alternatives to their original livelihood strategies and have returned to the flood plains. Depending on the type of adaptation measure that is being monitored and evaluated with indicators - project, policy or programme - the above challenges have varying significance. For example, developing and using indicators for projects is relatively easy, as many projects are undertaken within sectors where established monitoring and evaluation systems with proven indicators already exist. However, monitoring and evaluation of programmes and policies is more complex: it requires strong coordination across sectors and levels and is more susceptible to external factors, such as the overall regulatory and legislative environment. Current progress in monitoring and evaluating the implementation of adaptation projects, policies and programmes, including of costs and effectiveness Monitoring and evaluation is undertaken for different adaptation measures at various levels and in and across a variety of sectors. According to the submissions and other relevant information, adaptation policies are usually implemented, monitored and evaluated at national level (chapter II B 1 below), whereas programmes and projects have a sectoral or subnational, including local-level, focus (chapter II B 2 below). Efforts to monitor and evaluate adaptation strategies, policies and plans National-level policies, strategies and plans can provide an overarching strategic framework for adaptation, as well as an enabling environment in which subnational and local governments, the public sector and the private sector are provided with incentives and regulation to engage in adaptation actions. As Parties are at different stages in preparing, developing and implementing national adaptation strategies, policies and plans, progress in monitoring and evaluating adaptation varies considerably. Efforts range from fully implemented and evaluated strategies, as seen in Finland, to partial implementation and plans for developing national monitoring systems, as in Spain, to acknowledging progress in the implementation of national-level adaptation efforts and pledging that future efforts will include monitoring, as in Singapore, to recognizing the need to develop a comprehensive multi-sectoral national adaptation action plan, as is the case in Jordan. The majority of efforts currently undertaken to monitor national adaptation policies, plans and strategies relate: To monitoring, reporting and sharing knowledge during implementation; To evaluation during implementation and at conclusion. In terms of monitoring, reporting and sharing knowledge during implementation, the Netherlands, in its contribution to the EU submission referred to in paragraph 2 above, reports on engaging a wide range of stakeholders, including central government, regions, municipalities and water boards, in the implementation of the National Programme on Climate Adaptation and Spatial Planning. To ensure effective implementation, knowledge is shared through the Knowledge For Climate programme, where the public sector, the private sector and scientific institutions cooperate on `hotspots', such as the main national airport, the harbour of Rotterdam, the major rivers and the south-western delta. In Spain, implementation of measures under the national Climate Change Adaptation Strategy is monitored by national authorities and other stakeholders. The Spanish Climate Change Office ensures consistency and cohesion across all the working lines and sectoral projects covered by the strategy, and information sharing is facilitated through a working group on impacts and adaptation. According to the EU submission, several of its member States are working on providing the overarching legal, institutional and technical environment for evaluation of adaptation plans and practices at national and local level. The EU suggests that such integrated approaches allow rapid accumulation of knowledge, avoid duplication of work and are more cost-effective than running isolated projects. It argues that integrative monitoring and evaluation provides the flexibility and robustness that adaptation planning requires to adjust to uncertainties and new insights and to take account of changing stakeholder attitudes to risk. In comparison with monitoring, evaluation of adaptation policies is still an emerging area where little progress has been made. If evaluation does take place, it focuses more on the process of implementation than on the effectiveness of implemented policies and strategies. A review of European national adaptation strategies found that only Finland, Germany and the United Kingdom have put in place formal procedures for review, monitoring and evaluation, and make use or plan to make use of indicators. The focus of evaluation varies: whereas Finland and Germany seek to evaluate the implementation of adaptation measures along sector lines, the United Kingdom seeks to evaluate the implementation of adaptation at different administrative levels. The United Kingdom, under its 2008 Local Government Performance Framework, introduced a `planning to adapt' indicator for local authorities and partners to monitor and evaluate progress in adapting to climate change. In addition, short- and long-term indicators of the progress and effectiveness of the overall Adapting To Climate Change programme are under development. Finland, when evaluating progress made in implementing its 2005 National Adaptation Strategy, used an indicator to conclude that the country's average level of adaptation scores 2 on a scale from 1 to 5. Table 2 provides an overview of the process-based indicators used by Finland and the United Kingdom to evaluate progress in adaptation. Besides having different foci - Finland's indicator focuses on sectors whereas the United Kingdom's indicator focuses on local governments - the indicators have different scales, 1 - 5 versus 0 - 4, making it difficult to compare overall results. Table 2. Comparison of process-based indicators used to evaluate progress in adaptation in Finland and the United Kingdom Level of adaptationa Indicators used by the United Kingdom Indicators used by Finland Getting started Potential threats and opportunities across estate and services starting to be assessed Next steps to build on that assessment identified and agreed upon Need for adaptation recognized among a group of pioneers in the sector Little research done on the impacts of or adaptation to climate change Some adaptation measures identified but not yet implemented Public commitment and impacts assessment Public commitment made to identify, communicate and manage climate-related risk Local risk-based assessment of significant vulnerabilities and opportunities made Need for adaptation measures recognized to some extent in the sector Impacts of climate change known indicatively (qualitative information), taking account of the uncertainty involved in climate change scenarios Adaptation measures identified and plans made for their implementation, some of them launched Comprehensive risk assessment Comprehensive risk-based assessment undertaken and priority risks for services identified Most effective adaptive responses identified and incorporated in council strategies, plans, partnerships and operations Adaptive responses implemented in some priority areas Need for adaptation measures quite well recognized in the sector Impacts quite well known, taking into account uncertainty Adaptation measures identified and their implementation launched Cross-sectoral cooperation on adaptation measures started Comprehensive action plan Climate impacts and risks embedded across council decision-making Comprehensive adaptation action plan developed Adaptive responses implemented in all priority areas Need for adaptation measures widely recognized and accepted in the sector Adaptation incorporated into regular decision-making processes Impacts well known, within the limits of uncertainty Implementation of adaptation measures widely launched and their benefits assessed at least to some extent Cross-sectoral cooperation on adaptation measures an established practice Implementation, monitoring and continuous review Comprehensive adaptation action plan across the local authority area implemented Robust process for regular and continual monitoring and review exists to ensure progress with each measure and updating of objectives Appropriate adaptive responses implemented Adaptation measures under the adaptation strategy or recognized otherwise implemented in the sector a The United Kingdom's scale is 0 - 4, Finland's scale is 1 - 5. Source: Finnish Ministry of Agriculture and Forestry. 2009. Evaluation of the Implementation of Finland's National Strategy for Adaptation to Climate Change 2009. Available at <www.mmm.fi/attachments/mmm/julkaisut/julkaisusarja/2009/ 5IEsngZYQ/Adaptation_Strategy_evaluation.pdf> and British Local and Regional Partnership Board. 2008. Adapting to Climate Change. Guidance notes for NI188. Available at <www.lga.gov.uk/lga/aio/1382855>. Efforts in monitoring and evaluating adaptation policies are also undertaken by several countries as part of environmental auditing, which encompasses a range of activities, including auditing measures taken to promote the efficiency and effectiveness of policies. As part of the 2008 - 2010 work plan of the Working Group on Environmental Auditing of the International Organization of Supreme Audit Institutions, 14 supreme audit institutions (SAIs) have agreed to cooperate in designing and undertaking coordinated audits of climate change, including adaptation, in order to encourage and support effective national audits and to develop a consistent audit approach. During an adaptation audit, an SAI may inquire whether the responsible ministries have undertaken a vulnerability assessment to identify climate change risks; whether the government has an overarching policy, plan or strategy in place; whether the governance of adaptation is efficient (in terms of roles and responsibilities); and whether the policy instruments are effective. So far, adaptation audits have examined only short-term adaptation efforts such as emergency planning or flood defences. For example, the SAI of the United Republic of Tanzania examined how well national and regional agencies have implemented the national strategic guidance on disaster management, in particular regarding prevention and reduction of floods. The audit concluded that there is a high risk that possible future floods will cause further damage in the country, owing to an absence of strategic disaster management planning and a lack of preparedness in handling disasters, including a lack of coordination, among regional and local authorities. Efforts to monitor and evaluate adaptation programmes and projects Monitoring and evaluation of adaptation programmes and projects is more advanced than that of adaptation policies and strategies, in particular regarding cost-effectiveness. Programmes and projects are more short term and tend to be implemented in individual sectors or local areas, where monitoring, reporting and evaluation systems are already established. Many adaptation projects and programmes implemented in developing countries receive financial support from bilateral and multilateral funds. A number of funds, including the Adaptation Fund, the Least Developed Countries Fund (LDCF) and the Special Climate Change Fund, have adopted or are in the process of developing adaptation-specific, results-based management (RBM) frameworks. These RBM frameworks incorporate monitoring and reporting at three levels: at programme, or fund, level; at the level of the sectors or areas of intervention; and at project level. As with similar efforts seen elsewhere, monitoring and evaluation will include monitoring progress in implementing adaptation measures and evaluating the effectiveness of supported adaptation activities through a combination of process-based and outcome-based indicators. Under the RBM frameworks, each project requires baseline data and its own set of sector-based output and outcome indicators, in order for project managers and evaluators to assess the progress made and whether it has achieved its stated objectives. In the area of health, for example, the Piloting Climate Change Adaptation to Protect Human Health project which is implemented in several developing countries uses the proportion of health-care facilities reporting climate-sensitive health risk data on a weekly basis as an indicator to assess the effectiveness of enhancing early warning systems. In the area of agriculture, the Benin Integrated Adaptation Programme to Combat the Effects of Climate Change on Agricultural Production and Food Security project seeks to reduce the risk of climate-induced impacts on agriculture productivity as one of its outcomes. This will be assessed through the following indicators: (1) number of farmers (including pastoralists) and fishermen engaged in capacity development activities for climate change risk management, and (2) percentage change in adaptive capacity among demonstration villages, assessed with a perception-based survey. Setting up and carrying out effective monitoring and evaluation requires substantial human and financial resources. For example, the estimated monitoring and evaluation budget of the four-year Pacific Adaptation to Climate Change project implemented by UNDP and the Secretariat of the Pacific Regional Environment Programme is USD 410,000. This covers annual project reports, project implementation reviews, regular progress and thematic reports and independent mid-term and final evaluations. However, such costs and requirements usually exceed the budgets and capacity of many community-based adaptation (CBA) projects. For this reason, UNDP has developed a simplified tool to monitor and evaluate locally-driven adaptation projects. The tool, a vulnerability reduction assessment (VRA), is a form of participatory impact assessment that focuses on community perceptions of vulnerability to climate change, and capacity to adapt. The VRA is based on four indicator questions, which are tailored to capture locally relevant vulnerability issues and are posed during a series of three or four community meetings over the period of a CBA project. Responses to the questions take the form of a numerical score, provided by the respondents during these community meetings. Repeated evaluations of community perceptions of project effectiveness and climate change risks give an indication of the change in vulnerability relative to baseline values established before project activities began. The VRA was designed to be flexible and adapted to different circumstances. For example, in Guatemala the VRA was used in conjunction with a local tool called Almanario, which is an oversized flip-chart-style booklet designed to allow semi-literate communities to define the key elements of a project. The majority of adaptation projects and programmes supported by the funds mentioned above are either under development or under implementation; few have been concluded and evaluated. Preliminary programme evaluations have been undertaken for the Strategic Priority on Adaptation (SPA) initiative of the Global Environment Facility (GEF) and the LDCF. As of October 2008, all of the resources under the SPA had been committed. The independent GEF Evaluation Office (EO) is currently undertaking a final evaluation. The joint evaluation of the LDCF, undertaken by the GEF EO and the EO of the Ministry of Foreign Affairs of Denmark, was aimed at analysing and documenting the results and lessons learned from the use of the LDCF in financing and promoting adaptation. The evaluation focused on procedural aspects and deliverables such as national adaptation programmes of action (NAPAs). Given that none of the priority projects identified by LDCs in their NAPAs have been concluded, the study did not include an assessment of the effectiveness of the NAPAs in addressing urgent and immediate adaptation needs. The evaluation of projects, in particular their overall effectiveness, is limited. For example, economic aspects of the Capacity Building to Enable the Development of Adaptation Measures in Pacific Island Countries project were independently evaluated once the project was completed. The project, which took place between January 2002 and March 2005, involved the design and implementation of adaptation measures in nine pilots in four Pacific island nations: Cook Islands, Fiji, Samoa and Vanuatu. The evaluation concluded with the following lessons learned: to keep better records of costs; to specify viable alternatives at project design stage to ensure adoption of least-cost approaches; to specify a framework for monitoring benefits of the project, including by listing and projecting expected measurable benefits so as to measure expected benefits against defined targets; and to ensure continuous monitoring. The 2009 report of the Mainstreaming Adaptation to Climate Change (MACC) project in the Caribbean stressed the importance of a functioning monitoring and evaluation system to the overall success of the project. In particular, the mid-term review proved to be crucial as it allowed changes to be made in the project design, including a change in executing agency, which eventually led to its success. However, the report also notes that a more simplified project design and the setting up of a more efficient monitoring and evaluation system that was more systematic and less intense and involved less frequent reporting would have been more effective. Other evaluations of adaptation projects and programmes focus on intended and unintended effects, both direct and indirect. In its submission, for example, Wetlands International reported on the outcomes of its Green Coasts project, which was implemented between August 2005 and June 2009. This project aimed at restoring coastal ecosystems such as mangroves, beach forest, coral reef and sand dunes in areas of India, Indonesia, Malaysia, Sri Lanka and Thailand which had been damaged by the 2004 tsunami. The total costs of the project amounted to EUR 1.5 million, and the project benefited 91,000 tsunami-affected people. Evaluation of the project results and outcomes shows that besides the direct and intended benefits, an additional 12,000 people have benefited from increased income from livelihood activities supported by Green Coast such as fishing, small-scale aquaculture, eco-enterprises, home gardening and livestock farming. Conclusions, lessons learned, good practices, gaps and needs The submissions and additional information reviewed for this document demonstrate that a range of efforts are being undertaken in monitoring and evaluating the implementation of adaptation projects, policies and programmes, although some areas are more advanced than others. The majority of adaptation projects, policies and programmes are either under development or under implementation and only a few have been concluded. The Colombian Integrated National Adaptation Programme, for example, which was one of the first adaptation projects in Latin America, is not expected to be concluded until 2011. As a result, most monitoring and evaluation efforts are currently undertaken as part of ongoing implementation. Only a few focus on evaluating projects, policies and programmes after their conclusion, and there have been no evaluations undertaken a few years after an adaptation measure was concluded, although Finland, for example, plans to undertake a more comprehensive evaluation of its adaptation strategy and its effectiveness within six to eight years (i.e. 2011 - 2013) of the publication of the strategy. This chapter highlights some of the lessons learned and good practices identified in monitoring and evaluating the implementation of adaptation projects, policies and programmes, as well as remaining gaps and needs. Lessons learned and good practices Despite the limited experience, a number of lessons learned and good practices have been identified for developing and using a sound monitoring and evaluation system, including the application of indicators. The first is that consideration of monitoring and evaluation systems for adaptation projects, policies and programmes should be included in the design of an adaptation measure and may include: To make use of existing monitoring and evaluation systems to the extent possible; To engage broadly with stakeholders at all levels and in and across all relevant sectors; To agree on mechanisms, institutions and criteria, including roles and responsibilities, for monitoring and evaluation. As for using systems for monitoring and evaluation, many efforts, such as the MACC project, have shown that they are essential for ensuring the success of adaptation measures. Continued monitoring and regular evaluation ensures that good as well as maladaptive practices are recognized and can then be shared with a large number of adaptation stakeholders. Despite existing challenges, the benefits of developing and using indicators to monitor and evaluate adaptation are considerable. Indicators can be used to compare the situation after the adaptation measure was implemented with the initial conditions prior to implementation or with conditions of a control site that represents how the system would have performed in the absence of the measure. Given that adaptation projects, policies and programmes are still at a relatively early stage of implementation, it is likely that process-based indicators will continue to play an important role. However, enhancing outcome-based indicators is probably desirable to allow for an assessment of the effectiveness of the adaptation measure. Regarding the type of adaptation indicators that planners and practitioners should select, it is suggested that a mix of quantitative, qualitative and narrative tools be used, including surveys and scorecards, so that results can be `triangulated' to give the most accurate picture possible of progress towards adaptation and the factors involved. Gaps and needs Gaps and needs remain despite earlier calls for progress on monitoring and evaluation of adaptation measures. For example, participants at the Nairobi work programme workshop on adaptation planning and practices held in Rome, Italy, from 10 to 12 September 2007, recommended that Parties develop country-driven, indicator-based monitoring and evaluation systems for adaptation in different sectors and levels to identify good practices and maladaptation. While some progress has been made with regard to monitoring and evaluation of adaptation projects using indicators, progress is less pronounced for adaptation policies and programmes. Often this relates to the fact that many adaptation policies and programmes lack measurable targets or clearly defined expected outcomes. Without these, indicators cannot be used to evaluate effectiveness. Given the range of possible adaptation indicators, the European Environment Agency sees a need for an agreement, for example on a regional scale, on the definition of key climate change indicators, including extreme weather events (e.g. `floods' and `droughts'), and to define operational ways of tracking impacts in multiple sectors, over a variety of timescales and geographical scales. Other gaps that hinder the development and use of effective monitoring and evaluation systems for adaptation projects, policies and programmes include: Lack of financial, human and technical resources and capacities; Lack of good baseline data and historical trends to allow for an analysis of effectiveness; Insufficient reporting and exchange of data and information, in particular when adaptation measures are implemented by a range of stakeholders across levels and sectors. Issues for further consideration In view of the information in this document, it is clear that monitoring and evaluation of adaptation projects, policies and programmes and development and usage of indicators is still evolving and that a number of issues need to be further investigated. Parties may wish to consider the following: How can monitoring and evaluation of adaptation measures make the best use of existing monitoring and evaluation systems, including existing indicators? Could these systems be used as they are, do they need to be revised or are new and additional systems required? What are the advantages and disadvantages of each of these approaches? What kinds and combinations of process and outcome indicators would be most suitable for monitoring and evaluating adaptation policies, programmes and projects? In the light of the multi-sectoral, multi-scale and multi-stakeholder nature of adaptation, how should monitoring and evaluation of adaptation policies, programmes and projects take place? What roles and responsibilities need to be assigned? How can results from monitoring and reporting be reported and disseminated so as to ensure that they are fed back into the project, policy or programme concerned but also to allow for lessons learned and good practices identified to be shared with the wider community of adaptation planners and practitioners? 